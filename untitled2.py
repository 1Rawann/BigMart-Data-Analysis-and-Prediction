# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oHCUNsbO9eif5oeIkaunnwfirOYazp04
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split

# Read the CSV file
train_df = pd.read_csv('/content/Train.csv')

# Print the first few rows of the data
train_df.head()

# Read the CSV file
test_df = pd.read_csv('/content/Test.csv')

# Print the first few rows of the data
test_df.head()

#check for missing values
print(train_df.isnull().sum())

#check for missing values
print(test_df.isnull().sum())

#function to clean numerical columns from nulls
def clean_column(df, col_name):
    Q1 = df[col_name].quantile(0.25)
    Q3 = df[col_name].quantile(0.75)
    IQR = Q3 - Q1
    upper_limit = Q3 + (1.5 * IQR)
    lower_limit = Q1 - (1.5 * IQR)

    for x in df.index:
        if df.loc[x, col_name] > upper_limit:
            df.loc[x, col_name] = upper_limit
        elif df.loc[x, col_name] < lower_limit:
            df.loc[x, col_name] = lower_limit

    mean = df[col_name].mean()
    df[col_name].replace(np.nan, mean, inplace=True)

    print(df.isnull().sum())

clean_column(train_df, 'Item_Weight')
clean_column(test_df, 'Item_Weight')

mode = train_df['Outlet_Size'].mode()[0]
train_df['Outlet_Size'].fillna(mode, inplace=True)
print(train_df.isnull().sum())

mode = test_df['Outlet_Size'].mode()[0]
test_df['Outlet_Size'].fillna(mode, inplace=True)
print(test_df.isnull().sum())

# Loop through each column in the DataFrame object
for col in train_df.columns:
    # Check if the column is categorical
    if train_df[col].dtype == 'object':
        # Count the number of unique categories in the column
        num_categories = len(train_df[col].unique())
        print(f"{col} has {num_categories} categories")

# Loop through each column in the DataFrame object
for col in test_df.columns:
    # Check if the column is categorical
    if test_df[col].dtype == 'object':
        # Count the number of unique categories in the column
        num_categories = len(test_df[col].unique())
        print(f"{col} has {num_categories} categories")

def one_hot_encode(df, col_name):
    # Perform one-hot encoding on the specified categorical column
    df_onehot = pd.get_dummies(df[col_name], prefix=col_name)

    # Concatenate the one-hot encoded columns with the original DataFrame object
    df = pd.concat([df, df_onehot], axis=1)

    # Drop the original categorical column
    df.drop(col_name, axis=1, inplace=True)

    return df

train_df = one_hot_encode(train_df, 'Item_Fat_Content')
train_df = one_hot_encode(train_df, 'Item_Type')
train_df = one_hot_encode(train_df, 'Outlet_Identifier')
train_df = one_hot_encode(train_df, 'Outlet_Size')
train_df= one_hot_encode(train_df, 'Outlet_Location_Type')
train_df = one_hot_encode(train_df, 'Outlet_Type')

train_df.head()

test_df = one_hot_encode(test_df, 'Item_Fat_Content')
test_df = one_hot_encode(test_df, 'Item_Type')
test_df = one_hot_encode(test_df, 'Outlet_Identifier')
test_df = one_hot_encode(test_df, 'Outlet_Size')
test_df= one_hot_encode(test_df, 'Outlet_Location_Type')
test_df = one_hot_encode(test_df, 'Outlet_Type')

test_df.head()

sns.heatmap(train_df.corr())

#feature selection

X = train_df[['Item_Weight','Item_Fat_Content','Item_Visibility','Item_Type','Item_MRP','Outlet_Identifier','Outlet_Establishment_Year','Outlet_Size','Outlet_Location_Type']]
y = train_df['Item_Outlet_Sales']

# Split the data
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Fit the model
model = LinearRegression()
model.fit(X_train, y_train)

# Validate the model
y_pred_val = model.predict(X_val)
mse_val = mean_squared_error(y_val, y_pred_val)
rmse_val = mean_squared_error(y_val, y_pred_val, squared=False)
r2_val = r2_score(y_val, y_pred_val)

# Test the model
X_test = test_df
y_pred_test = model.predict(X_test)
mse_test = mean_squared_error(y, y_pred_test)
rmse_test = mean_squared_error(y, y_pred_test, squared=False)
r2_test = r2_score(y, y_pred_test)

#random forest model
from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier()
xx=np.ravel(x_train)
yy=np.ravel(y_train)
rfc.fit(x_train, yy)
y_pred = rfc.predict(x_test)

# Calculate the accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Create a confusion matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion matrix:")
print(cm)

# Create a classification report
report = classification_report(y_test, y_pred)
print("Classification report:")
print(report)

# Calculate the mean squared error
mse = mean_squared_error(y_test, y_pred)
print("Mean squared error:", mse)

